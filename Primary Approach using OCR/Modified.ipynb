{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import re\n",
    "import openpyxl\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(pdf_path):\n",
    "    \"\"\"Extract metadata from the PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    metadata = doc.metadata\n",
    "    doc.close()\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_by_page(pdf_path, output_path=\"extracted_text.txt\"):\n",
    "    \"\"\"Extract text directly from the PDF page by page.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_text = []\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        all_text.append(f\"--- Page {page_num + 1} ---\\n{text}\\n\")\n",
    "    \n",
    "    full_text = \"\\n\".join(all_text)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_text)\n",
    "    \n",
    "    doc.close()\n",
    "    return full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_content(img_array):\n",
    "    \"\"\"Check if an image has meaningful content based on standard deviation.\"\"\"\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY) if len(img_array.shape) == 3 else img_array\n",
    "    std_dev = np.std(gray)\n",
    "    return std_dev > 10  # Threshold for meaningful content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_and_diagrams(pdf_path, output_folder=\"extracted_images\"):\n",
    "    \"\"\"Extract images and diagrams from PDF.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    doc = fitz.open(pdf_path)\n",
    "    image_count = 0\n",
    "    image_paths = []\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        print(f\"Processing page {page_num+1} for images...\")\n",
    "        \n",
    "        # Get images from page\n",
    "        image_list = page.get_images(full=True)\n",
    "        \n",
    "        # Extract each image\n",
    "        for img_index, img_info in enumerate(image_list):\n",
    "            try:\n",
    "                xref = img_info[0]\n",
    "                base_image = doc.extract_image(xref)\n",
    "                image_bytes = base_image[\"image\"]\n",
    "                image_ext = base_image[\"ext\"]\n",
    "                \n",
    "                # Convert bytes to numpy array for analysis\n",
    "                img = np.array(Image.open(BytesIO(image_bytes)))\n",
    "                \n",
    "                # Skip if image doesn't have meaningful content\n",
    "                if not has_content(img):\n",
    "                    continue\n",
    "                \n",
    "                # Save the image\n",
    "                image_count += 1\n",
    "                image_filename = f\"{output_folder}/image_p{page_num+1}_{img_index+1}.{image_ext}\"\n",
    "                with open(image_filename, \"wb\") as img_file:\n",
    "                    img_file.write(image_bytes)\n",
    "                image_paths.append(image_filename)\n",
    "                print(f\"  - Saved embedded image: {image_filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - Error extracting image {img_index} on page {page_num+1}: {e}\")\n",
    "        \n",
    "        # For diagrams and other objects not detected as standard images\n",
    "        print(f\"  Looking for diagrams on page {page_num+1}...\")\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Higher resolution for better OCR\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Use contour detection to find potential diagrams\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        thresh = cv2.threshold(blurred, 230, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        \n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        print(f\"  - Found {len(contours)} potential diagram contours\")\n",
    "        \n",
    "        # Filter contours based on size and shape\n",
    "        diagram_count = 0\n",
    "        for i, contour in enumerate(contours):\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area < 10000:  # Skip small contours\n",
    "                continue\n",
    "                \n",
    "            # Get bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            \n",
    "            # Skip if rectangle is too large (likely the whole page)\n",
    "            if w > pix.width * 0.9 or h > pix.height * 0.9:\n",
    "                continue\n",
    "                \n",
    "            # Extract potential diagram\n",
    "            diagram = img_array[y:y+h, x:x+w]\n",
    "            \n",
    "            # Skip if low content variation (likely a solid area)\n",
    "            if not has_content(diagram):\n",
    "                continue\n",
    "            \n",
    "            # Save diagram\n",
    "            diagram_img = Image.fromarray(diagram)\n",
    "            diagram_filename = f\"{output_folder}/diagram_p{page_num+1}_{i+1}.png\"\n",
    "            diagram_img.save(diagram_filename)\n",
    "            image_paths.append(diagram_filename)\n",
    "            diagram_count += 1\n",
    "        \n",
    "        print(f\"  - Saved {diagram_count} diagrams from page {page_num+1}\")\n",
    "    \n",
    "    print(f\"Total images and diagrams extracted: {len(image_paths)}\")\n",
    "    doc.close()\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_table_like(text_block):\n",
    "    \"\"\"Check if a text block resembles a table structure.\"\"\"\n",
    "    # Check for structured rows (consistent patterns of spaces/tabs)\n",
    "    lines = text_block.strip().split('\\n')\n",
    "    if len(lines) < 3:  # Too few lines to be a table\n",
    "        return False\n",
    "    \n",
    "    # Check for delimiter patterns (multiple spaces, tabs, or |)\n",
    "    delim_patterns = [re.compile(r'\\s{3,}'), re.compile(r'\\t+'), re.compile(r'\\|')]\n",
    "    delim_matches = [any(pattern.search(line) for pattern in delim_patterns) for line in lines]\n",
    "    \n",
    "    # If most lines have delimiter patterns, might be a table\n",
    "    if sum(delim_matches) / len(lines) > 0.7:\n",
    "        return True\n",
    "    \n",
    "    # Check for aligned columns (words starting at consistent positions)\n",
    "    positions = []\n",
    "    for line in lines:\n",
    "        word_positions = [match.start() for match in re.finditer(r'\\b\\w+', line)]\n",
    "        if word_positions:\n",
    "            positions.append(word_positions)\n",
    "    \n",
    "    if positions:\n",
    "        # Count how many positions are common across lines\n",
    "        position_counts = {}\n",
    "        for pos_list in positions:\n",
    "            for pos in pos_list:\n",
    "                position_counts[pos] = position_counts.get(pos, 0) + 1\n",
    "        \n",
    "        # If we have consistent starting positions across many lines, likely a table\n",
    "        consistent_positions = sum(1 for count in position_counts.values() if count > len(lines) * 0.5)\n",
    "        if consistent_positions >= 2:  # At least 2 aligned columns\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def preprocess_table_text(text):\n",
    "    \"\"\"Preprocess text to better extract tables.\"\"\"\n",
    "    # Replace multiple spaces with a single delimiter for parsing\n",
    "    text = re.sub(r'\\s{3,}', '|', text)\n",
    "    # Replace tabs with delimiter\n",
    "    text = re.sub(r'\\t+', '|', text)\n",
    "    # Clean up extra spaces around delimiters\n",
    "    text = re.sub(r'\\s*\\|\\s*', '|', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text_to_table(text):\n",
    "    \"\"\"Parse table-like text into a pandas DataFrame.\"\"\"\n",
    "    lines = text.strip().split('\\n')\n",
    "    rows = []\n",
    "    \n",
    "    # Convert text lines to list of values\n",
    "    for line in lines:\n",
    "        # Skip empty lines\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        \n",
    "        # Different parsing strategies\n",
    "        if '|' in line:\n",
    "            # Pipe-delimited\n",
    "            row = [cell.strip() for cell in line.split('|')]\n",
    "        else:\n",
    "            # Space-aligned table\n",
    "            # First, identify consistent column positions by finding clusters of word starts\n",
    "            all_positions = []\n",
    "            for l in lines:\n",
    "                word_positions = [match.start() for match in re.finditer(r'\\b\\w+', l)]\n",
    "                all_positions.extend(word_positions)\n",
    "            \n",
    "            # Cluster positions (treat positions within 2 chars as the same column)\n",
    "            clusters = []\n",
    "            for pos in sorted(all_positions):\n",
    "                found = False\n",
    "                for i, cluster in enumerate(clusters):\n",
    "                    if abs(cluster - pos) <= 2:\n",
    "                        clusters[i] = min(cluster, pos)  # Use leftmost position\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    clusters.append(pos)\n",
    "            \n",
    "            # Use positions to split the line\n",
    "            row = []\n",
    "            clusters = sorted(clusters)\n",
    "            for i in range(len(clusters)):\n",
    "                start = clusters[i]\n",
    "                end = clusters[i+1] if i+1 < len(clusters) else len(line)\n",
    "                if start < len(line):\n",
    "                    cell = line[start:end].strip()\n",
    "                    row.append(cell)\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    # Ensure all rows have the same number of columns\n",
    "    max_cols = max(len(row) for row in rows) if rows else 0\n",
    "    for i in range(len(rows)):\n",
    "        while len(rows[i]) < max_cols:\n",
    "            rows[i].append(\"\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # If first row looks like header (different pattern or all strings)\n",
    "    if len(rows) > 1:\n",
    "        # Check if first row has different formatting\n",
    "        first_row_numeric = sum(1 for cell in rows[0] if cell.strip() and cell.strip().replace('.', '', 1).isdigit())\n",
    "        other_rows_numeric = sum(1 for row in rows[1:] for cell in row if cell.strip() and cell.strip().replace('.', '', 1).isdigit())\n",
    "        \n",
    "        if (first_row_numeric / max(1, len([c for c in rows[0] if c.strip()]))) < 0.3 and \\\n",
    "           (other_rows_numeric / max(1, sum(1 for row in rows[1:] for c in row if c.strip()))) > 0.3:\n",
    "            # First row is likely a header\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df.iloc[1:]\n",
    "    \n",
    "    # Reset index\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_from_text(text):\n",
    "    \"\"\"Extract tables from text content by identifying table-like structures.\"\"\"\n",
    "    tables = []\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        # Look for a sequence of lines that might form a table\n",
    "        table_start = i\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1  # Skip empty lines\n",
    "        \n",
    "        table_text = []\n",
    "        while i < len(lines) and lines[i].strip():\n",
    "            table_text.append(lines[i])\n",
    "            i += 1\n",
    "        \n",
    "        if table_text:\n",
    "            text_block = '\\n'.join(table_text)\n",
    "            if is_table_like(text_block):\n",
    "                processed_text = preprocess_table_text(text_block)\n",
    "                table_df = parse_text_to_table(processed_text)\n",
    "                \n",
    "                # Only add if it looks like a real table (at least 2x2)\n",
    "                if table_df.shape[0] >= 2 and table_df.shape[1] >= 2:\n",
    "                    tables.append({\n",
    "                        'page_range': f\"{table_start}-{i}\",\n",
    "                        'table': table_df\n",
    "                    })\n",
    "        \n",
    "        i += 1  # Move to next line\n",
    "    \n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables_with_ocr(pdf_path):\n",
    "    \"\"\"Extract tables using PyMuPDF and augmented with OCR.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    tables = []\n",
    "    \n",
    "    for page_num, page in enumerate(doc):\n",
    "        print(f\"Processing page {page_num+1} for tables...\")\n",
    "        \n",
    "        # Get text directly from PDF\n",
    "        text = page.get_text(\"text\")\n",
    "        \n",
    "        # Try to extract tables from regular text\n",
    "        text_tables = extract_tables_from_text(text)\n",
    "        for table_info in text_tables:\n",
    "            table_info['page'] = page_num + 1\n",
    "            tables.append(table_info)\n",
    "        \n",
    "        print(f\"  - Found {len(text_tables)} tables from text on page {page_num+1}\")\n",
    "        \n",
    "        # Use OCR for additional table detection\n",
    "        print(f\"  - Using OCR to detect additional tables...\")\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # Higher resolution\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Use OpenCV to detect table-like structures\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        \n",
    "        # Detect lines that might form table structure\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 100, minLineLength=100, maxLineGap=10)\n",
    "        \n",
    "        if lines is not None and len(lines) > 10:  # Enough lines might indicate a table\n",
    "            # Use OCR on the page to get potential table content\n",
    "            print(f\"  - Found {len(lines)} lines, running OCR for tables...\")\n",
    "            ocr_text = pytesseract.image_to_string(img)\n",
    "            ocr_tables = extract_tables_from_text(ocr_text)\n",
    "            \n",
    "            for table_info in ocr_tables:\n",
    "                table_info['page'] = page_num + 1\n",
    "                table_info['source'] = 'ocr'\n",
    "                tables.append(table_info)\n",
    "            \n",
    "            print(f\"  - Found {len(ocr_tables)} additional tables with OCR\")\n",
    "        else:\n",
    "            print(f\"  - No significant table structure detected with OpenCV\")\n",
    "    \n",
    "    print(f\"Total tables extracted: {len(tables)}\")\n",
    "    doc.close()\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import re\n",
    "\n",
    "def clean_excel_value(value):\n",
    "    \"\"\"Remove illegal characters that cannot be written to an Excel file.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        ILLEGAL_CHARACTERS_RE = re.compile(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]')  # Matches non-printable ASCII\n",
    "        return ILLEGAL_CHARACTERS_RE.sub(\"\", value)  # Remove illegal characters\n",
    "    return value  # Return non-string values as is\n",
    "\n",
    "\n",
    "\n",
    "def save_tables_to_excel(tables, output_file=\"extracted_tables.xlsx\"):\n",
    "    \"\"\"Save tables to Excel with each table on its own sheet.\"\"\"\n",
    "    if not tables:\n",
    "        print(\"No tables to save.\")\n",
    "        return 0\n",
    "        \n",
    "    wb = openpyxl.Workbook()\n",
    "    # Remove default sheet\n",
    "    if \"Sheet\" in wb.sheetnames:\n",
    "        del wb[\"Sheet\"]\n",
    "    \n",
    "    # Group tables by page\n",
    "    tables_by_page = {}\n",
    "    for table_info in tables:\n",
    "        page = table_info.get('page', 'unknown')\n",
    "        if page not in tables_by_page:\n",
    "            tables_by_page[page] = []\n",
    "        tables_by_page[page].append(table_info)\n",
    "    \n",
    "    # Create sheets and populate with tables\n",
    "    for page, page_tables in tables_by_page.items():\n",
    "        for i, table_info in enumerate(page_tables):\n",
    "            sheet_name = f\"Page{page}_Table{i+1}\"\n",
    "            if len(sheet_name) > 31:  # Excel has 31 char limit for sheet names\n",
    "                sheet_name = f\"P{page}_T{i+1}_{uuid.uuid4().hex[:5]}\"\n",
    "            \n",
    "            ws = wb.create_sheet(sheet_name)\n",
    "            \n",
    "            # Write table to sheet\n",
    "            df = table_info['table']\n",
    "            for r_idx, row in enumerate(dataframe_to_rows(df, index=False, header=True)):\n",
    "                for c_idx, value in enumerate(row):\n",
    "                    clean_value = clean_excel_value(value)  # Clean illegal characters\n",
    "                    ws.cell(row=r_idx+1, column=c_idx+1, value=clean_value)\n",
    "\n",
    "                \n",
    "    wb.save(output_file)\n",
    "    print(f\"Saved {len(tables)} tables to {output_file}\")\n",
    "    return len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ocr_to_images(image_paths, output_file=\"ocr_from_images.txt\"):\n",
    "    \"\"\"Apply OCR to extracted images.\"\"\"\n",
    "    if not image_paths:\n",
    "        print(\"No images to process for OCR.\")\n",
    "        return \"\"\n",
    "        \n",
    "    ocr_text = []\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            print(f\"Applying OCR to {os.path.basename(img_path)}...\")\n",
    "            img = Image.open(img_path)\n",
    "            text = pytesseract.image_to_string(img)\n",
    "            if text.strip():\n",
    "                ocr_text.append(f\"--- OCR from {os.path.basename(img_path)} ---\")\n",
    "                ocr_text.append(text)\n",
    "                print(f\"  - Extracted {len(text.split())} words\")\n",
    "            else:\n",
    "                print(f\"  - No text found\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Error OCR-ing image {img_path}: {e}\")\n",
    "    \n",
    "    # Save OCR text\n",
    "    full_ocr_text = \"\\n\\n\".join(ocr_text)\n",
    "    if full_ocr_text:\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_ocr_text)\n",
    "        print(f\"Saved OCR text to {output_file}\")\n",
    "    else:\n",
    "        print(\"No OCR text to save\")\n",
    "    \n",
    "    return full_ocr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text_sources(pdf_text, ocr_text, output_file=\"combined_text.txt\"):\n",
    "    \"\"\"Combine regular PDF text extraction with OCR results.\"\"\"\n",
    "    combined = pdf_text + \"\\n\\n--- OCR EXTRACTED TEXT ---\\n\\n\" + ocr_text\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(combined)\n",
    "    print(f\"Combined text saved to {output_file}\")\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path, output_folder=\"pdf_extraction_results\"):\n",
    "    \"\"\"Process a PDF and extract all possible content.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Set output paths\n",
    "    text_output = os.path.join(output_folder, \"extracted_text.txt\")\n",
    "    ocr_output = os.path.join(output_folder, \"ocr_text.txt\")\n",
    "    combined_output = os.path.join(output_folder, \"combined_text.txt\")\n",
    "    tables_output = os.path.join(output_folder, \"extracted_tables.xlsx\")\n",
    "    images_output_folder = os.path.join(output_folder, \"images\")\n",
    "    \n",
    "    # Step 1: Extract metadata\n",
    "    print(\"\\n1. Extracting metadata...\")\n",
    "    metadata = extract_metadata(pdf_path)\n",
    "    print(f\"Metadata: {metadata}\")\n",
    "    \n",
    "    # Step 2: Extract text\n",
    "    print(\"\\n2. Extracting text...\")\n",
    "    pdf_text = extract_text_by_page(pdf_path, text_output)\n",
    "    print(f\"Extracted {len(pdf_text.split())} words, saved to {text_output}\")\n",
    "    \n",
    "    # Step 3: Extract images and diagrams\n",
    "    print(\"\\n3. Extracting images and diagrams...\")\n",
    "    image_paths = extract_images_and_diagrams(pdf_path, images_output_folder)\n",
    "    \n",
    "    # Step 4: Apply OCR to images\n",
    "    print(\"\\n4. Applying OCR to extracted images...\")\n",
    "    images_ocr_text = apply_ocr_to_images(image_paths, ocr_output)\n",
    "    \n",
    "    # Step 5: Combine text sources\n",
    "    print(\"\\n5. Combining text sources...\")\n",
    "    combined_text = combine_text_sources(pdf_text, images_ocr_text, combined_output)\n",
    "    \n",
    "    # Step 6: Extract tables\n",
    "    print(\"\\n6. Extracting tables...\")\n",
    "    tables = extract_tables_with_ocr(pdf_path)\n",
    "    \n",
    "    # Step 7: Save tables to Excel\n",
    "    print(\"\\n7. Saving tables to Excel...\")\n",
    "    table_count = save_tables_to_excel(tables, tables_output)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n=== EXTRACTION SUMMARY ===\")\n",
    "    print(f\"Total PDF pages: {fitz.open(pdf_path).page_count}\")\n",
    "    print(f\"Text extraction: {len(pdf_text.split())} words\")\n",
    "    print(f\"Images extracted: {len(image_paths)}\")\n",
    "    print(f\"OCR text: {len(images_ocr_text.split()) if images_ocr_text else 0} words\")\n",
    "    print(f\"Tables extracted: {table_count}\")\n",
    "    print(f\"All results saved to: {output_folder}\")\n",
    "    \n",
    "    return {\n",
    "        \"metadata\": metadata,\n",
    "        \"text_path\": text_output,\n",
    "        \"combined_text_path\": combined_output,\n",
    "        \"images_count\": len(image_paths),\n",
    "        \"tables_count\": table_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Extracting metadata...\n",
      "Metadata: {'format': 'PDF 1.4', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'iOS Version 15.1 (Build 19B74) Quartz PDFContext', 'creationDate': \"D:20211206105506Z00'00'\", 'modDate': \"D:20211206105506Z00'00'\", 'trapped': '', 'encryption': None}\n",
      "\n",
      "2. Extracting text...\n",
      "Extracted 10618 words, saved to pdf_extraction_results\\extracted_text.txt\n",
      "\n",
      "3. Extracting images and diagrams...\n",
      "Processing page 1 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p1_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p1_2.png\n",
      "  Looking for diagrams on page 1...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 1\n",
      "Processing page 2 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p2_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p2_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p2_3.jpeg\n",
      "  Looking for diagrams on page 2...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 2\n",
      "Processing page 3 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_3.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_4.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_5.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p3_6.jpeg\n",
      "  Looking for diagrams on page 3...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 3\n",
      "Processing page 4 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_3.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_4.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_5.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p4_6.jpeg\n",
      "  Looking for diagrams on page 4...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 4\n",
      "Processing page 5 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p5_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p5_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p5_3.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p5_4.jpeg\n",
      "  Looking for diagrams on page 5...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 5\n",
      "Processing page 6 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p6_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p6_2.png\n",
      "  Looking for diagrams on page 6...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 6\n",
      "Processing page 7 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p7_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p7_2.png\n",
      "  Looking for diagrams on page 7...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 7\n",
      "Processing page 8 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p8_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p8_2.png\n",
      "  Looking for diagrams on page 8...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 8\n",
      "Processing page 9 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p9_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p9_2.png\n",
      "  Looking for diagrams on page 9...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 9\n",
      "Processing page 10 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p10_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p10_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p10_3.png\n",
      "  Looking for diagrams on page 10...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 10\n",
      "Processing page 11 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p11_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p11_2.png\n",
      "  Looking for diagrams on page 11...\n",
      "  - Found 33 potential diagram contours\n",
      "  - Saved 0 diagrams from page 11\n",
      "Processing page 12 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p12_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p12_2.png\n",
      "  Looking for diagrams on page 12...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 12\n",
      "Processing page 13 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p13_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p13_2.png\n",
      "  Looking for diagrams on page 13...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 13\n",
      "Processing page 14 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p14_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p14_2.png\n",
      "  Looking for diagrams on page 14...\n",
      "  - Found 20 potential diagram contours\n",
      "  - Saved 0 diagrams from page 14\n",
      "Processing page 15 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p15_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p15_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p15_3.jpeg\n",
      "  Looking for diagrams on page 15...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 15\n",
      "Processing page 16 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p16_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p16_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p16_3.jpeg\n",
      "  Looking for diagrams on page 16...\n",
      "  - Found 14 potential diagram contours\n",
      "  - Saved 0 diagrams from page 16\n",
      "Processing page 17 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p17_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p17_2.png\n",
      "  Looking for diagrams on page 17...\n",
      "  - Found 14 potential diagram contours\n",
      "  - Saved 0 diagrams from page 17\n",
      "Processing page 18 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p18_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p18_2.png\n",
      "  Looking for diagrams on page 18...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 18\n",
      "Processing page 19 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p19_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p19_2.png\n",
      "  Looking for diagrams on page 19...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 19\n",
      "Processing page 20 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p20_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p20_2.png\n",
      "  Looking for diagrams on page 20...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 20\n",
      "Processing page 21 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p21_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p21_2.png\n",
      "  Looking for diagrams on page 21...\n",
      "  - Found 14 potential diagram contours\n",
      "  - Saved 0 diagrams from page 21\n",
      "Processing page 22 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p22_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p22_2.png\n",
      "  Looking for diagrams on page 22...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 22\n",
      "Processing page 23 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p23_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p23_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p23_3.jpeg\n",
      "  Looking for diagrams on page 23...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 23\n",
      "Processing page 24 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p24_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p24_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p24_3.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p24_4.png\n",
      "  Looking for diagrams on page 24...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 24\n",
      "Processing page 25 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p25_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p25_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p25_3.jpeg\n",
      "  Looking for diagrams on page 25...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 25\n",
      "Processing page 26 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p26_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p26_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p26_3.jpeg\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p26_4.png\n",
      "  Looking for diagrams on page 26...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 26\n",
      "Processing page 27 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p27_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p27_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p27_3.png\n",
      "  Looking for diagrams on page 27...\n",
      "  - Found 14 potential diagram contours\n",
      "  - Saved 0 diagrams from page 27\n",
      "Processing page 28 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p28_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p28_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p28_3.png\n",
      "  Looking for diagrams on page 28...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 28\n",
      "Processing page 29 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_2.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_3.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_4.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_5.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_6.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p29_7.png\n",
      "  Looking for diagrams on page 29...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 29\n",
      "Processing page 30 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p30_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p30_2.png\n",
      "  Looking for diagrams on page 30...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 30\n",
      "Processing page 31 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p31_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p31_2.png\n",
      "  Looking for diagrams on page 31...\n",
      "  - Found 14 potential diagram contours\n",
      "  - Saved 0 diagrams from page 31\n",
      "Processing page 32 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p32_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p32_2.png\n",
      "  Looking for diagrams on page 32...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 32\n",
      "Processing page 33 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p33_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p33_2.png\n",
      "  Looking for diagrams on page 33...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 33\n",
      "Processing page 34 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p34_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p34_2.png\n",
      "  Looking for diagrams on page 34...\n",
      "  - Found 13 potential diagram contours\n",
      "  - Saved 0 diagrams from page 34\n",
      "Processing page 35 for images...\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p35_1.png\n",
      "  - Saved embedded image: pdf_extraction_results\\images/image_p35_2.png\n",
      "  Looking for diagrams on page 35...\n",
      "  - Found 40 potential diagram contours\n",
      "  - Saved 0 diagrams from page 35\n",
      "Total images and diagrams extracted: 97\n",
      "\n",
      "4. Applying OCR to extracted images...\n",
      "Applying OCR to image_p1_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p1_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p2_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p2_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p2_3.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p3_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p3_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p3_3.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p3_4.png...\n",
      "  - Extracted 9 words\n",
      "Applying OCR to image_p3_5.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p3_6.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p4_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p4_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p4_3.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p4_4.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p4_5.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p4_6.jpeg...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p5_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p5_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p5_3.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p5_4.jpeg...\n",
      "  - No text found\n",
      "Applying OCR to image_p6_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p6_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p7_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p7_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p8_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p8_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p9_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p9_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p10_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p10_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p10_3.png...\n",
      "  - Extracted 89 words\n",
      "Applying OCR to image_p11_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p11_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p12_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p12_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p13_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p13_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p14_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p14_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p15_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p15_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p15_3.jpeg...\n",
      "  - Extracted 4 words\n",
      "Applying OCR to image_p16_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p16_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p16_3.jpeg...\n",
      "  - Extracted 55 words\n",
      "Applying OCR to image_p17_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p17_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p18_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p18_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p19_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p19_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p20_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p20_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p21_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p21_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p22_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p22_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p23_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p23_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p23_3.jpeg...\n",
      "  - Extracted 31 words\n",
      "Applying OCR to image_p24_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p24_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p24_3.jpeg...\n",
      "  - Extracted 50 words\n",
      "Applying OCR to image_p24_4.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p25_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p25_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p25_3.jpeg...\n",
      "  - Extracted 59 words\n",
      "Applying OCR to image_p26_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p26_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p26_3.jpeg...\n",
      "  - Extracted 97 words\n",
      "Applying OCR to image_p26_4.png...\n",
      "  - Extracted 7 words\n",
      "Applying OCR to image_p27_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p27_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p27_3.png...\n",
      "  - Extracted 6 words\n",
      "Applying OCR to image_p28_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p28_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p28_3.png...\n",
      "  - Extracted 40 words\n",
      "Applying OCR to image_p29_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p29_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p29_3.png...\n",
      "  - Extracted 1 words\n",
      "Applying OCR to image_p29_4.png...\n",
      "  - Extracted 4 words\n",
      "Applying OCR to image_p29_5.png...\n",
      "  - Extracted 1 words\n",
      "Applying OCR to image_p29_6.png...\n",
      "  - Extracted 1 words\n",
      "Applying OCR to image_p29_7.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p30_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p30_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p31_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p31_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p32_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p32_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p33_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p33_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p34_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p34_2.png...\n",
      "  - Extracted 2 words\n",
      "Applying OCR to image_p35_1.png...\n",
      "  - No text found\n",
      "Applying OCR to image_p35_2.png...\n",
      "  - Extracted 2 words\n",
      "Saved OCR text to pdf_extraction_results\\ocr_text.txt\n",
      "\n",
      "5. Combining text sources...\n",
      "Combined text saved to pdf_extraction_results\\combined_text.txt\n",
      "\n",
      "6. Extracting tables...\n",
      "Processing page 1 for tables...\n",
      "  - Found 0 tables from text on page 1\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 591 lines, running OCR for tables...\n",
      "  - Found 1 additional tables with OCR\n",
      "Processing page 2 for tables...\n",
      "  - Found 2 tables from text on page 2\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 450 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 3 for tables...\n",
      "  - Found 2 tables from text on page 3\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 488 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 4 for tables...\n",
      "  - Found 5 tables from text on page 4\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 342 lines, running OCR for tables...\n",
      "  - Found 3 additional tables with OCR\n",
      "Processing page 5 for tables...\n",
      "  - Found 1 tables from text on page 5\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 262 lines, running OCR for tables...\n",
      "  - Found 0 additional tables with OCR\n",
      "Processing page 6 for tables...\n",
      "  - Found 1 tables from text on page 6\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 499 lines, running OCR for tables...\n",
      "  - Found 5 additional tables with OCR\n",
      "Processing page 7 for tables...\n",
      "  - Found 5 tables from text on page 7\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 740 lines, running OCR for tables...\n",
      "  - Found 8 additional tables with OCR\n",
      "Processing page 8 for tables...\n",
      "  - Found 1 tables from text on page 8\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 484 lines, running OCR for tables...\n",
      "  - Found 4 additional tables with OCR\n",
      "Processing page 9 for tables...\n",
      "  - Found 5 tables from text on page 9\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 581 lines, running OCR for tables...\n",
      "  - Found 4 additional tables with OCR\n",
      "Processing page 10 for tables...\n",
      "  - Found 3 tables from text on page 10\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 318 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 11 for tables...\n",
      "  - Found 5 tables from text on page 11\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 643 lines, running OCR for tables...\n",
      "  - Found 4 additional tables with OCR\n",
      "Processing page 12 for tables...\n",
      "  - Found 1 tables from text on page 12\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 366 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 13 for tables...\n",
      "  - Found 0 tables from text on page 13\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 275 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 14 for tables...\n",
      "  - Found 1 tables from text on page 14\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 324 lines, running OCR for tables...\n",
      "  - Found 3 additional tables with OCR\n",
      "Processing page 15 for tables...\n",
      "  - Found 1 tables from text on page 15\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 347 lines, running OCR for tables...\n",
      "  - Found 1 additional tables with OCR\n",
      "Processing page 16 for tables...\n",
      "  - Found 4 tables from text on page 16\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 375 lines, running OCR for tables...\n",
      "  - Found 4 additional tables with OCR\n",
      "Processing page 17 for tables...\n",
      "  - Found 6 tables from text on page 17\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 182 lines, running OCR for tables...\n",
      "  - Found 3 additional tables with OCR\n",
      "Processing page 18 for tables...\n",
      "  - Found 1 tables from text on page 18\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 340 lines, running OCR for tables...\n",
      "  - Found 3 additional tables with OCR\n",
      "Processing page 19 for tables...\n",
      "  - Found 3 tables from text on page 19\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 462 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 20 for tables...\n",
      "  - Found 0 tables from text on page 20\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 351 lines, running OCR for tables...\n",
      "  - Found 0 additional tables with OCR\n",
      "Processing page 21 for tables...\n",
      "  - Found 5 tables from text on page 21\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 605 lines, running OCR for tables...\n",
      "  - Found 5 additional tables with OCR\n",
      "Processing page 22 for tables...\n",
      "  - Found 0 tables from text on page 22\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 441 lines, running OCR for tables...\n",
      "  - Found 1 additional tables with OCR\n",
      "Processing page 23 for tables...\n",
      "  - Found 1 tables from text on page 23\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 410 lines, running OCR for tables...\n",
      "  - Found 1 additional tables with OCR\n",
      "Processing page 24 for tables...\n",
      "  - Found 1 tables from text on page 24\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 172 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 25 for tables...\n",
      "  - Found 2 tables from text on page 25\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 322 lines, running OCR for tables...\n",
      "  - Found 1 additional tables with OCR\n",
      "Processing page 26 for tables...\n",
      "  - Found 1 tables from text on page 26\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 264 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 27 for tables...\n",
      "  - Found 4 tables from text on page 27\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 384 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 28 for tables...\n",
      "  - Found 2 tables from text on page 28\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 638 lines, running OCR for tables...\n",
      "  - Found 3 additional tables with OCR\n",
      "Processing page 29 for tables...\n",
      "  - Found 1 tables from text on page 29\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 280 lines, running OCR for tables...\n",
      "  - Found 0 additional tables with OCR\n",
      "Processing page 30 for tables...\n",
      "  - Found 0 tables from text on page 30\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 268 lines, running OCR for tables...\n",
      "  - Found 0 additional tables with OCR\n",
      "Processing page 31 for tables...\n",
      "  - Found 11 tables from text on page 31\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 265 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Processing page 32 for tables...\n",
      "  - Found 1 tables from text on page 32\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 397 lines, running OCR for tables...\n",
      "  - Found 0 additional tables with OCR\n",
      "Processing page 33 for tables...\n",
      "  - Found 7 tables from text on page 33\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 535 lines, running OCR for tables...\n",
      "  - Found 5 additional tables with OCR\n",
      "Processing page 34 for tables...\n",
      "  - Found 3 tables from text on page 34\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 740 lines, running OCR for tables...\n",
      "  - Found 4 additional tables with OCR\n",
      "Processing page 35 for tables...\n",
      "  - Found 1 tables from text on page 35\n",
      "  - Using OCR to detect additional tables...\n",
      "  - Found 244 lines, running OCR for tables...\n",
      "  - Found 2 additional tables with OCR\n",
      "Total tables extracted: 172\n",
      "\n",
      "7. Saving tables to Excel...\n",
      "Saved 172 tables to pdf_extraction_results\\extracted_tables.xlsx\n",
      "\n",
      "=== EXTRACTION SUMMARY ===\n",
      "Total PDF pages: 35\n",
      "Text extraction: 10618 words\n",
      "Images extracted: 97\n",
      "OCR text: 788 words\n",
      "Tables extracted: 172\n",
      "All results saved to: pdf_extraction_results\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to your PDF file\n",
    "pdf_path = r\"E:\\Btech_AI\\Intern\\ocrpro\\Phable CAM Final.pdf\"  # Replace with your actual PDF path\n",
    "\n",
    "# Process the PDF\n",
    "results = process_pdf(pdf_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
