{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Proposal Summary December 2021  \\nBorrower Name: Terrals Technologies Pvt. Ltd.  \\nSector: Chronic Disease Management and Healthcare Services Platform  \\nProposed Amount: Up to INR 45,00,00,000  \\nTranche 1: INR 10,00,00,000  \\nTranche 2: Up to 15% of the equity raise (Series B) with an overall cap of INR 35Cr  \\nTenor: 18 months from the date of disbursement of each tranche  \\nDebt XIRR: 16.56%; Warrants: 7%; XIRR with warrant upside: 31.2%  \\nRepayment Schedule: Quarterly Amortization (5 installments); Moratorium for three months i.e., first principal installment at the end of 6 months. The coupons are to be serviced monthly on the last day of each month.  \\n\\nFiltering Criteria:  \\nEquity Raised till Date more than INR 50Cr, Pre-Equity INR 64Cr, Post-Equity INR 192 Cr.  \\nDebt to Equity Raised including proposed debt less than 15 percent, Pre-Equity 15.9 percent, Post-Equity 15.16 percent.  \\nDebt to Valuation including proposed debt less than 5 percent, Pre-Equity 6.6 percent.  \\nMonths of Runwa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ground truth text from the input PDF using pdfplumber\n",
    "input_pdf_path = r\"E:\\Btech_AI\\Intern\\ocrpro\\Phable CAM Final.pdf\"\n",
    "file_ground = r\"E:\\Btech_AI\\Intern\\ocrpro\\Phable_CAM_Final_extracted.txt\"\n",
    "\n",
    "with open(file_ground, \"r\", encoding=\"utf-8\") as f:\n",
    "    ground_truth_text = f.read().strip()\n",
    "\n",
    "\n",
    "# Display first 1000 characters for verification\n",
    "ground_truth_text[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted text from both approaches\n",
    "file_primary = r\"Primary Approach using OCR/Output-Primary Approach/extracted_text-PrimaryApproach.txt\"\n",
    "file_mistral = r\"E:\\Btech_AI\\Intern\\ocrpro\\LLM Approach\\Finalised-Mistral-outputs\\text_output-mistral.txt\"\n",
    "\n",
    "with open(file_primary, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_primary = f.read().strip()\n",
    "\n",
    "with open(file_mistral, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_mistral = f.read().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Primary OCR Approach': {'WER': 0.4335989010989011,\n",
       "  'CER': 0.0002393824881465662,\n",
       "  'BLEU Score': 0.19176308831890435},\n",
       " 'Mistral AI OCR Approach': {'WER': 0.455514652014652,\n",
       "  'CER': 0.000635141871039722,\n",
       "  'BLEU Score': 0.15085038483938618}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "# Function to compute WER and CER in chunks\n",
    "def chunked_error_rate(reference, hypothesis, chunk_size=500):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "\n",
    "    ref_chunks = [ref_words[i: i + chunk_size] for i in range(0, len(ref_words), chunk_size)]\n",
    "    hyp_chunks = [hyp_words[i: i + chunk_size] for i in range(0, len(hyp_words), chunk_size)]\n",
    "\n",
    "    wer_scores, cer_scores = [], []\n",
    "\n",
    "    for r_chunk, h_chunk in zip(ref_chunks, hyp_chunks):\n",
    "        wer_scores.append(len(set(r_chunk) - set(h_chunk)) / len(r_chunk))  # WER Approximation\n",
    "        cer_scores.append(len(set(\"\".join(r_chunk)) - set(\"\".join(h_chunk))) / len(\"\".join(r_chunk)))  # CER Approximation\n",
    "\n",
    "    return np.mean(wer_scores), np.mean(cer_scores)\n",
    "\n",
    "# Compute chunked WER and CER\n",
    "wer_primary, cer_primary = chunked_error_rate(ground_truth_text, text_primary)\n",
    "wer_mistral, cer_mistral = chunked_error_rate(ground_truth_text, text_mistral)\n",
    "\n",
    "# Compute BLEU Score in chunks\n",
    "def chunked_bleu(reference, hypothesis, chunk_size=500):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "\n",
    "    ref_chunks = [ref_words[i: i + chunk_size] for i in range(0, len(ref_words), chunk_size)]\n",
    "    hyp_chunks = [hyp_words[i: i + chunk_size] for i in range(0, len(hyp_words), chunk_size)]\n",
    "\n",
    "    bleu_scores = [sentence_bleu([r_chunk], h_chunk) for r_chunk, h_chunk in zip(ref_chunks, hyp_chunks)]\n",
    "    \n",
    "    return np.mean(bleu_scores)\n",
    "\n",
    "bleu_primary = chunked_bleu(ground_truth_text, text_primary)\n",
    "bleu_mistral = chunked_bleu(ground_truth_text, text_mistral)\n",
    "\n",
    "# Output results\n",
    "{\n",
    "    \"Primary OCR Approach\": {\n",
    "        \"WER\": wer_primary,\n",
    "        \"CER\": cer_primary,\n",
    "        \"BLEU Score\": bleu_primary\n",
    "    },\n",
    "    \"Mistral AI OCR Approach\": {\n",
    "        \"WER\": wer_mistral,\n",
    "        \"CER\": cer_mistral,\n",
    "        \"BLEU Score\": bleu_mistral\n",
    "    }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
