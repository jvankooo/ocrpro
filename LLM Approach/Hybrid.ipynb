{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text extraction complete. Saved in extracted_text.txt.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, output_txt=\"extracted_text.txt\"):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF and applies OCR where necessary.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :param output_txt: Path to save extracted text.\n",
    "    :return: Extracted text.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        if not text.strip():  # If no embedded text, use OCR\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            text = pytesseract.image_to_string(img)\n",
    "\n",
    "        full_text += f\"\\n\\n--- Page {page_num+1} ---\\n\\n\" + text\n",
    "\n",
    "    # Save the text to a file\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(full_text)\n",
    "\n",
    "    return full_text\n",
    "\n",
    "# Example usage\n",
    "pdf_path = r\"E:\\Btech_AI\\Intern\\ocrpro\\Phable CAM Final.pdf\"  # Replace with actual PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "print(\"✅ Text extraction complete. Saved in extracted_text.txt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 46 tables using pdfplumber.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tables_with_pdfplumber(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts tables using pdfplumber.\n",
    "    :param pdf_path: Path to the PDF file.\n",
    "    :return: List of DataFrames.\n",
    "    \"\"\"\n",
    "    tables = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            extracted_tables = page.extract_tables()\n",
    "            for table in extracted_tables:\n",
    "                df = pd.DataFrame(table).replace(\"\", None)\n",
    "                if df.shape[1] > 1 and df.shape[0] > 1:  # Ignore non-tables\n",
    "                    tables.append(df)\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Extract tables\n",
    "tables_pdfplumber = extract_tables_with_pdfplumber(pdf_path)\n",
    "print(f\"✅ Extracted {len(tables_pdfplumber)} tables using pdfplumber.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 41 tables successfully aligned.\n"
     ]
    }
   ],
   "source": [
    "def align_columns(df):\n",
    "    \"\"\"\n",
    "    Attempts to realign misaligned columns in a table.\n",
    "    :param df: DataFrame with potential misalignment.\n",
    "    :return: Re-aligned DataFrame.\n",
    "    \"\"\"\n",
    "    if df.empty or df.shape[1] == 0:  # ✅ Handle empty tables\n",
    "        return None\n",
    "\n",
    "    df = df.dropna(how='all')  # Remove empty rows\n",
    "\n",
    "    if df.empty or df.shape[1] == 0:  # ✅ Check again after dropping empty rows\n",
    "        return None\n",
    "\n",
    "    # If there’s a row with more columns, use it as the header\n",
    "    try:\n",
    "        max_cols = max(df.apply(lambda x: x.count(), axis=1))  # Get the row with most non-null values\n",
    "        for idx, row in df.iterrows():\n",
    "            if row.count() == max_cols:\n",
    "                df.columns = row\n",
    "                df = df.iloc[idx + 1:]  # Remove the header row from data\n",
    "                break\n",
    "    except ValueError:\n",
    "        return None  # ✅ Return None if column alignment fails\n",
    "\n",
    "    return df.reset_index(drop=True).fillna(\"\")\n",
    "\n",
    "# ✅ Filter out empty tables before processing\n",
    "aligned_tables = [align_columns(df) for df in tables_pdfplumber if df is not None]\n",
    "aligned_tables = [df for df in aligned_tables if df is not None]  # Remove None values\n",
    "\n",
    "def ensure_unique_columns(df):\n",
    "    \"\"\"\n",
    "    Ensures all column names in the DataFrame are unique.\n",
    "    :param df: Pandas DataFrame.\n",
    "    :return: DataFrame with unique column names.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return df\n",
    "    \n",
    "    seen = {}\n",
    "    new_columns = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in seen:\n",
    "            seen[col] += 1\n",
    "            new_columns.append(f\"{col}_{seen[col]}\")\n",
    "        else:\n",
    "            seen[col] = 0\n",
    "            new_columns.append(col)\n",
    "\n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "# Apply unique column renaming to all extracted tables\n",
    "aligned_tables = [ensure_unique_columns(df) for df in aligned_tables]\n",
    "\n",
    "print(f\"✅ {len(aligned_tables)} tables successfully aligned.\")\n",
    "\n",
    "\n",
    "def merge_multiline_headers(df, max_header_rows=2):\n",
    "    \"\"\"\n",
    "    Merges multi-line headers into a single row.\n",
    "    :param df: Pandas DataFrame.\n",
    "    :param max_header_rows: Number of rows to consider as headers.\n",
    "    :return: DataFrame with merged headers.\n",
    "    \"\"\"\n",
    "    if df.empty or df.shape[1] == 0:\n",
    "        return df\n",
    "\n",
    "    # Limit to max_header_rows and fill empty header spaces\n",
    "    header_rows = df.iloc[:max_header_rows].fillna(\"\")\n",
    "    \n",
    "    # Merge headers into a single row\n",
    "    merged_header = [\" \".join(str(col).strip() for col in row if str(col).strip()) for row in zip(*header_rows.values)]\n",
    "    \n",
    "    # Assign new headers and remove original header rows\n",
    "    df.columns = merged_header\n",
    "    df = df.iloc[max_header_rows:].reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply to all extracted tables\n",
    "aligned_tables = [merge_multiline_headers(df) for df in aligned_tables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def refine_tables_with_llama(tables):\n",
    "    \"\"\"\n",
    "    Uses a local LLaMA model via Ollama to refine table structure.\n",
    "    :param tables: List of Pandas DataFrames.\n",
    "    :return: List of refined DataFrames.\n",
    "    \"\"\"\n",
    "    tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an AI that structures tables extracted from PDFs. \"\n",
    "        \"Format them into structured JSON without extra text. \"\n",
    "        \"Ensure the output is in this format: \"\n",
    "        '{\"tables\": [{\"columns\": [\"col1\", \"col2\"], \"rows\": [[\"row1_col1\", \"row1_col2\"], ...]}]}. '\n",
    "        \"Here are the extracted tables:\\n\"\n",
    "        f\"{json.dumps(tables_json_safe)}\"\n",
    "    )\n",
    "\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "    try:\n",
    "        # ✅ Extract response safely\n",
    "        response_text = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "        if not response_text:  # ✅ Check for empty response\n",
    "            raise ValueError(\"LLaMA returned an empty response.\")\n",
    "\n",
    "        # ✅ Remove Markdown formatting if present\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        refined_tables_json = json.loads(response_text)  \n",
    "\n",
    "        refined_tables = [pd.DataFrame(table[\"rows\"], columns=table[\"columns\"]) for table in refined_tables_json[\"tables\"]]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error parsing LLaMA output: {e}\")\n",
    "        refined_tables = tables  # Use original tables if parsing fails\n",
    "\n",
    "    return refined_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_8664\\1766809467.py:11: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "def refine_tables_with_mistral(tables):\n",
    "    \"\"\"\n",
    "    Uses Mistral via Ollama to refine table structure.\n",
    "    :param tables: List of Pandas DataFrames.\n",
    "    :return: List of refined DataFrames.\n",
    "    \"\"\"\n",
    "    tables_json_safe = [df.to_dict(orient=\"records\") for df in tables]\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an AI that structures tables extracted from PDFs. \"\n",
    "        \"Format them into structured JSON without extra text. \"\n",
    "        \"Ensure the output is in this format: \"\n",
    "        '{\"tables\": [{\"columns\": [\"col1\", \"col2\"], \"rows\": [[\"row1_col1\", \"row1_col2\"], ...]}]}. '\n",
    "        \"Here are the extracted tables:\\n\"\n",
    "        f\"{json.dumps(tables_json_safe)}\"\n",
    "    )\n",
    "\n",
    "    response = ollama.chat(model=\"mistral\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "\n",
    "    try:\n",
    "        response_text = response[\"message\"][\"content\"].strip()\n",
    "\n",
    "        if not response_text:\n",
    "            raise ValueError(\"Mistral returned an empty response.\")\n",
    "\n",
    "        if \"```json\" in response_text:\n",
    "            response_text = response_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "        refined_tables_json = json.loads(response_text)  \n",
    "\n",
    "        refined_tables = [pd.DataFrame(table[\"rows\"], columns=table[\"columns\"]) for table in refined_tables_json[\"tables\"]]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error parsing Mistral output: {e}\")\n",
    "        refined_tables = tables  \n",
    "\n",
    "    return refined_tables\n",
    "\n",
    "# Test both models\n",
    "refined_tables_llama = refine_tables_with_llama(aligned_tables)\n",
    "refined_tables_mistral = refine_tables_with_mistral(aligned_tables)\n",
    "\n",
    "# Compare results\n",
    "print(\"✅ Table structuring complete for LLaMA & Mistral.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder = \"output_tables\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def save_tables_to_excel(tables, output_excel):\n",
    "    \"\"\"\n",
    "    Saves structured tables in an Excel file (one sheet per table).\n",
    "    :param tables: List of DataFrames.\n",
    "    :param output_excel: Path to the Excel file.\n",
    "    \"\"\"\n",
    "    if not tables:\n",
    "        print(\"⚠ No tables to save.\")\n",
    "        return\n",
    "\n",
    "    with pd.ExcelWriter(output_excel) as writer:\n",
    "        for idx, df in enumerate(tables):\n",
    "            df.to_excel(writer, sheet_name=f\"Table_{idx+1}\", index=False)\n",
    "\n",
    "# Save structured tables\n",
    "output_excel = os.path.join(output_folder, \"final_tables.xlsx\")\n",
    "save_tables_to_excel(refined_tables, output_excel)\n",
    "print(f\"✅ Final structured tables saved in {output_excel}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
